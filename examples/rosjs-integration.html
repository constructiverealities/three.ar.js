<!--
/*
 * Copyright 2017 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<!DOCTYPE html>
<html lang="en">
<head>
    <title>three.ar.js - Boilerplate</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no,
  minimum-scale=1.0, maximum-scale=1.0">
    <style>
        body {
            font-family: monospace;
            margin: 0;
            overflow: hidden;
            position: fixed;
            width: 100%;
            height: 100vh;
            -webkit-user-select: none;
            user-select: none;
        }

        #info {
            position: absolute;
            left: 50%;
            bottom: 0;
            transform: translate(-50%, 0);
            margin: 1em;
            z-index: 10;
            display: block;
            width: 100%;
            line-height: 2em;
            text-align: center;
        }

        #info a, #info .title {
            padding: 0.4em 0.6em;
            border-radius: 0.1em;
        }

        #info a {
            color: rgba(255, 255, 255, 0.8);
            background-color: rgba(40, 40, 40, 0.6);
            font-weight: bold;
            text-decoration: none;
        }

        .title {
            color: rgba(255, 255, 255, 0.9);
            background-color: rgba(40, 40, 40, 0.4);
            margin-left: 0.2em;
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        div#messages {
            border: 1px solid black;
            height: 20px;
            width: 100%;
        }
        div#rgbTrigger{
            border: 1px solid black;
            height: 50px;
            width: 50px;
            left:50%
            background-color: red;
            position: absolute;
            z-index: 200000;
        }
        div#rgbTrigger.stable{
            background-color: green;
        }

        .ros-blink {
            position: absolute;
            top: 10px;
            width: 10px;
            left: 50%;
        }

        .blink-on {
            background-color: green;
        }

        .blink-off {
            background-color: red;
        }

    </style>

</head>
<body>
<div id="info">
    <a href="https://github.com/google-ar/three.ar.js">three.ar.js</a><span class="title">Boilerplate scene</span>
</div>
<div id="messages"></div>
<div id="rgbTrigger"></div>
<audio id="beep" src="../third_party/sound/beep-07.wav"></audio>
<script src="../third_party/eventemitter2/lib/eventemitter2.js"></script>
<script src="../third_party/roslib/roslib.js"></script>
<script src="../third_party/constructiverealities/rosTime.js"></script>
<script src="../third_party/three.js/three.js"></script>
<script src="../third_party/three.js/VRControls.js"></script>
<script src="../dist/three.ar.js"></script>
<script>
    var vrFrameData;
    var vrDisplay, vrControls, arView;
    var canvas, camera, scene, renderer;
    var BOX_DISTANCE = 1.5;
    var BOX_SIZE = 0.25;
    var BOX_QUANTITY = 6;
    var boxesAdded = false;
    var domElMessage = document.querySelector('div#messages');


    var rosBridge = new ROSLIB.Ros();
    var rosPoseStampedTopic;    //uninitialized until we've made the connection
    var rosSensorImageTopic;    //uninitialized until we've made the connection
    var rosMotionEventStableTopic;   //uninitialized until we've made the connection
    var motionStateStable = undefined;
    var beepSound = document.getElementById('beep');

    //todo, move this into a factory/controller
    var motionStateManager = {
        update: function (isStable) {
            this.motionStateStable = isStable;
            this.updateUi();
        },
        docEl: undefined,
        bind: function(el){
         this.docEl = el;
         this.docEl.onclick = function(that){
                return function(){
                    that.grabRGB()
                };
            }(this)
        },
        updateUi: function () {
            if (!this.renderCanvas){
                this.renderCanvas = document.querySelector('canvas.auto-generated-canvas')
            }
            if (this.docEl) {
                if (this.motionStateStable) {
                    if (!this.docEl.classList.contains('stable')) {
                        this.docEl.classList.add('stable');
                    }
                }
                else {
                    //the state is not stable
                    this.docEl.classList.remove('stable');
                }
            }
        },
        grabRGB: function(){
            if (!this.renderCanvas){
                console.warn("cannot grab RGB frame with no canvas");
                return;
            }

            if (!this.motionStateStable){
                console.warn("grabbing RGB disabled when state not stable");
                return;
            }

                //an attempt to get the pixel data directly from the gl canvas
                gl = this.renderCanvas.getContext('webgl');
                this.rgbWidth = gl.drawingBufferWidth;
                this.rgbHeight = gl.drawingBufferHeight;

                this.RgbaPixels = new Uint8Array(this.rgbWidth * this.rgbHeight * 4);
                renderer.render(scene, camera);
                gl.readPixels(0, 0, this.rgbWidth, this.rgbHeight , gl.RGBA, gl.UNSIGNED_BYTE, this.RgbaPixels);
                beepSound.play();

        },
        motionStateStable: undefined
    };

    motionStateManager.bind(document.querySelector("div#rgbTrigger"));


    rosBridge.on('error', function (error) {
        console.error(error);
        debugger;
    });
    rosBridge.on('close', function () {
        console.log("ros bridge connection closed");
    });
    rosBridge.on('connection', function () {
        console.log("ros bridge connected successfully...")
        //create the Stamped Pose Topic with the appropriate connection and type
        rosPoseStampedTopic = new ROSLIB.Topic({
                ros: rosBridge,
                name: '/lighthouse/1/pose',
                messageType: 'geometry_msgs/PoseStamped'
            }
        );

        //create the sensore Image Topic with the appropriate connection and type
        rosSensorImageTopic = new ROSLIB.Topic({
            ros: rosBridge,
            name: '/arCore/1/image',
            messageType: 'sensor_msgs/Image'
        });

        //create the bool values that the system will inform us to unlock the camera trigger
        rosMotionEventStableTopic = new ROSLIB.Topic({
            ros: rosBridge,
            name: '/motionEvents/Stable',
            messageType: 'std_msgs/Bool'
        });

        rosMotionEventStableTopic.subscribe(function (message) {
            console.log("incoming state change for /motionEvent/Stable...");
            motionStateManager.update(message.data);

        });

        // if this isn't a reconnect, initialize the augmented reality display
        if (!vrDisplay) {
            initializeArCore()
        }
    });

    rosBridge.connect('ws://capture-bot:9090');

    function initializeArCore() {
        /**
         * Use the `getARDisplay()` utility to leverage the WebVR API
         * to see if there are any AR-capable WebVR VRDisplays. Returns
         * a valid display if found. Otherwise, display the unsupported
         * browser message.
         */

        THREE.ARUtils.getARDisplay()
            .then(function (display) {
                if (display) {
                    vrDisplay = display;
                    init();
                } else {
                    THREE.ARUtils.displayUnsupportedMessage();
                }
            });

    }

    function updateMessage(newString) {
        domElMessage.innerText = Performance.now() + newString
    }


    function init() {
        // Setup the three.js rendering environment
        renderer = new THREE.WebGLRenderer({alpha: true});
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.autoClear = false;
        canvas = renderer.domElement;
        canvas.classList.add('auto-generated-canvas');
        document.body.appendChild(canvas);
        scene = new THREE.Scene();

        // Creating the ARView, which is the object that handles
        // the rendering of the camera stream behind the three.js
        // scene
        arView = new THREE.ARView(vrDisplay, renderer);

        // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
        // except when using an AR-capable browser, the camera uses
        // the projection matrix provided from the device, so that the
        // perspective camera's depth planes and field of view matches
        // the physical camera on the device.
        camera = new THREE.ARPerspectiveCamera(
            vrDisplay,
            60,
            window.innerWidth / window.innerHeight,
            vrDisplay.depthNear,
            vrDisplay.depthFar
        );

        // VRControls is a utility from three.js that applies the device's
        // orientation/position to the perspective camera, keeping our
        // real world and virtual world in sync.
        vrControls = new THREE.VRControls(camera);

        // Bind our event handlers
        window.addEventListener('resize', onWindowResize, false);

        // Kick off the render loop!
        update();
    }
    var sendPoseToRos = function (devicePose) {
        if (rosBridge.isConnected) {
            //pack up the device pose
            var payload = {
                header: {
                    seq: 1,
                    stamp: getRosTimeComponent(),
                    frame_id: 'ArCore_1'
                },
                pose: {
                    position: devicePose.position,
                    orientation: {
                        x: devicePose.quaternion.x,
                        y: devicePose.quaternion.y,
                        z: devicePose.quaternion.z,
                        w: devicePose.quaternion.w
                    }

                }
            };
            rosPoseStampedTopic.publish(payload);
        }
    };

    /**
     * The render loop, called once per frame. Handles updating
     * our scene and rendering.
     */

    function update() {
        // Render the device's camera stream on screen first of all.
        // It allows to get the right pose synchronized with the right frame.
//        vrDisplay.getFrameData(vrFrameData);
        renderer.clearColor();

        arView.render();

        // Update our camera projection matrix in the event that
        // the near or far planes have updated
        camera.updateProjectionMatrix();


        // Update our perspective camera's positioning
        vrControls.update();

        // If we have not added boxes yet, and we have positional
        // information applied to our camera (it can take a few seconds),
        // and the camera's Y position is not undefined or 0, create boxes
        if (!boxesAdded && !camera.position.y) {
            addBoxes();
        }

        if (camera.position.x) {
            sendPoseToRos({
                    position: camera.position,
                    quaternion: camera.quaternion
                }
            );
        }

        // Render our three.js virtual scene
        renderer.clearDepth();
        renderer.render(scene, camera);

        // Kick off the requestAnimationFrame to call this function
        // on the next frame
        requestAnimationFrame(update);


    }
    /**
     * On window resize, update the perspective camera's aspect ratio,
     * and call `updateProjectionMatrix` so that we can get the latest
     * projection matrix provided from the device
     */
    function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
    }

    /**
     * Once we have position information applied to our camera,
     * create some boxes at the same height as the camera
     */
    function addBoxes() {
        // Create some cubes around the origin point
        for (var i = 0; i < BOX_QUANTITY; i++) {
            var angle = Math.PI * 2 * (i / BOX_QUANTITY);
            var geometry = new THREE.BoxGeometry(BOX_SIZE, BOX_SIZE, BOX_SIZE);
            var material = new THREE.MeshNormalMaterial();
            var cube = new THREE.Mesh(geometry, material);
            cube.position.set(Math.cos(angle) * BOX_DISTANCE, camera.position.y - 0.25, Math.sin(angle) * BOX_DISTANCE);
            scene.add(cube);
        }

        // Flip this switch so that we only perform this once
        boxesAdded = true;
    }

</script>
</body>
</html>
